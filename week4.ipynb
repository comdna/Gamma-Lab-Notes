{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chi4omZLZbt4"
      },
      "source": [
        "In this work, you are required to train a model for dataset MNIST with PyTorch.\n",
        "\n",
        "在这项工作中，您需要使用PyTorch训练数据集MNIST的模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrA70ruIaN-A"
      },
      "source": [
        "Load dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dguqwltQ9TC4"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "train_data = MNIST(\n",
        "    root = \"data\",\n",
        "    download = True,\n",
        "    train = True,\n",
        "    transform = torchvision.transforms.ToTensor()\n",
        ")\n",
        "test_data = MNIST(\n",
        "    root = \"data\",\n",
        "    download = True,\n",
        "    train = False,\n",
        "    transform = torchvision.transforms.ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size = 64)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovgrtfvNa-VF"
      },
      "source": [
        "Model: you may select your favorite model and implement it in the following class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I_Bo3r3FbIWO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2IadIrIbU8V"
      },
      "source": [
        "Evaluation: you need to implement a pipeline to train your neural network  \n",
        "前向+反向"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0RKqr0UebjDf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "训练数据集大小: 60000\n",
            "测试数据集大小: 10000\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.297053\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.397685\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.273634\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.326324\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.255255\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.316700\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.159173\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.343541\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.306989\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.262896\n",
            "Epoch 0 - Average Loss: 0.3632\n",
            "Test set: Average loss: 0.0030, Accuracy: 9424/10000 (94.24%)\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.106606\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.177807\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.095757\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.185846\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.184074\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.233597\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.073174\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.257730\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.254069\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.205127\n",
            "Epoch 1 - Average Loss: 0.1574\n",
            "Test set: Average loss: 0.0019, Accuracy: 9616/10000 (96.16%)\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.075561\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.107943\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.080552\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.108380\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.112931\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.134578\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.056736\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.177153\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.158941\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.141394\n",
            "Epoch 2 - Average Loss: 0.1058\n",
            "Test set: Average loss: 0.0016, Accuracy: 9697/10000 (96.97%)\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.056711\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.083752\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.080907\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.058218\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.086759\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.094617\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.032814\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.124868\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.097599\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.121937\n",
            "Epoch 3 - Average Loss: 0.0778\n",
            "Test set: Average loss: 0.0014, Accuracy: 9718/10000 (97.18%)\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.039032\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.071654\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.066350\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.037277\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.100271\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.074727\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.023038\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.079466\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.057215\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.088152\n",
            "Epoch 4 - Average Loss: 0.0580\n",
            "Test set: Average loss: 0.0014, Accuracy: 9734/10000 (97.34%)\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "train_size = len(train_dataloader.dataset)\n",
        "print(f\"训练数据集大小: {train_size}\")\n",
        "test_size = len(test_dataloader.dataset)\n",
        "print(f\"测试数据集大小: {test_size}\")\n",
        "\n",
        "pass\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()  \n",
        "        output = model(data)  \n",
        "        loss = loss_func(output, target)  \n",
        "        loss.backward()  \n",
        "        optimizer.step()  \n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
        "                100. * batch_idx / len(train_dataloader), loss.item()))\n",
        "    \n",
        "    print('Epoch {} - Average Loss: {:.4f}'.format(epoch, total_loss / len(train_dataloader)))\n",
        "\n",
        "    # 测试集\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_dataloader:\n",
        "            output = model(data)\n",
        "            test_loss += loss_func(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_dataloader.dataset)\n",
        "    accuracy = 100. * correct / len(test_dataloader.dataset)\n",
        "    print('训练集: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
        "        test_loss, correct, len(test_dataloader.dataset), accuracy))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
