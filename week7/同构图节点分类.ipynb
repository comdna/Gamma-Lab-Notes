{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已知一部分节点的标签，对没贴标签的节点进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建一个2层的GNN模型\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        # 实例化SAGEConve，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregator_type是聚合函数的类型\n",
    "        self.conv1 = dglnn.SAGEConv(\n",
    "            in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv(\n",
    "            in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # 输入是节点的特征\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 3327\n",
      "  NumEdges: 9228\n",
      "  NumFeats: 3703\n",
      "  NumClasses: 6\n",
      "  NumTrainingSamples: 120\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "dataset=dgl.data.CiteseerGraphDataset()\n",
    "graph=dataset[0]\n",
    "node_features = graph.ndata['feat']\n",
    "node_labels = graph.ndata['label']\n",
    "# 训练 验证 测试\n",
    "train_mask = graph.ndata['train_mask']\n",
    "valid_mask = graph.ndata['val_mask']\n",
    "test_mask = graph.ndata['test_mask']\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估函数\n",
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7922090291976929\n",
      "1.778780460357666\n",
      "1.765681505203247\n",
      "1.7524446249008179\n",
      "1.738763451576233\n",
      "1.7244818210601807\n",
      "1.7095264196395874\n",
      "1.6939059495925903\n",
      "1.677585244178772\n",
      "1.6606031656265259\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "model = SAGE(in_feats=n_features, hid_feats=100, out_feats=n_labels)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    # 使用所有节点(全图)进行前向传播计算\n",
    "    logits = model(graph, node_features)\n",
    "    # 计算损失值\n",
    "    loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
    "    # 计算验证集的准确度\n",
    "    acc = evaluate(model, graph, node_features, node_labels, valid_mask)\n",
    "    # 进行反向传播计算\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异构图训练(从各种类型的边上获取信息)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Heterograph Conv model\n",
    "import numpy as np\n",
    "\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "        # 实例化HeteroGraphConv，in_feats是输入特征的维度，out_feats是输出特征的维度，aggregate是聚合函数的类型\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # 输入是节点的特征字典\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样例图\n",
    "n_users = 1000\n",
    "n_items = 500\n",
    "n_follows = 3000\n",
    "n_clicks = 5000\n",
    "n_dislikes = 500\n",
    "n_hetero_features = 10\n",
    "n_user_classes = 5\n",
    "n_max_clicks = 10\n",
    "\n",
    "follow_src = np.random.randint(0, n_users, n_follows)\n",
    "follow_dst = np.random.randint(0, n_users, n_follows)\n",
    "click_src = np.random.randint(0, n_users, n_clicks)\n",
    "click_dst = np.random.randint(0, n_items, n_clicks)\n",
    "dislike_src = np.random.randint(0, n_users, n_dislikes)\n",
    "dislike_dst = np.random.randint(0, n_items, n_dislikes)\n",
    "\n",
    "hetero_graph = dgl.heterograph({\n",
    "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
    "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
    "    ('user', 'click', 'item'): (click_src, click_dst),\n",
    "    ('item', 'clicked-by', 'user'): (click_dst, click_src),\n",
    "    ('user', 'dislike', 'item'): (dislike_src, dislike_dst),\n",
    "    ('item', 'disliked-by', 'user'): (dislike_dst, dislike_src)})\n",
    "\n",
    "hetero_graph.nodes['user'].data['feature'] = torch.randn(n_users, n_hetero_features)\n",
    "hetero_graph.nodes['item'].data['feature'] = torch.randn(n_items, n_hetero_features)\n",
    "hetero_graph.nodes['user'].data['label'] = torch.randint(0, n_user_classes, (n_users,))\n",
    "hetero_graph.edges['click'].data['label'] = torch.randint(1, n_max_clicks, (n_clicks,)).float()\n",
    "# randomly generate training masks on user nodes and click edges\n",
    "hetero_graph.nodes['user'].data['train_mask'] = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6)\n",
    "hetero_graph.edges['click'].data['train_mask'] = torch.zeros(n_clicks, dtype=torch.bool).bernoulli(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RGCN(n_hetero_features, 20, n_user_classes, hetero_graph.etypes)\n",
    "user_feats = hetero_graph.nodes['user'].data['feature']\n",
    "item_feats = hetero_graph.nodes['item'].data['feature']\n",
    "labels = hetero_graph.nodes['user'].data['label']\n",
    "train_mask = hetero_graph.nodes['user'].data['train_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 使用所有节点的特征进行前向传播计算，并提取输出的user节点嵌入\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhetero_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_features\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 计算损失值\u001b[39;00m\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits[train_mask], labels[train_mask])\n",
      "File \u001b[1;32md:\\PYTHON\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PYTHON\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m, in \u001b[0;36mRGCN.forward\u001b[1;34m(self, graph, inputs)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, inputs):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# 输入是节点的特征字典\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     h \u001b[38;5;241m=\u001b[39m {k: F\u001b[38;5;241m.\u001b[39mrelu(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m h\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     19\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(graph, h)\n",
      "File \u001b[1;32md:\\PYTHON\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\PYTHON\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\PYTHON\\Lib\\site-packages\\dgl\\nn\\pytorch\\hetero.py:208\u001b[0m, in \u001b[0;36mHeteroGraphConv.forward\u001b[1;34m(self, g, inputs, mod_args, mod_kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stype, etype, dtype \u001b[38;5;129;01min\u001b[39;00m g\u001b[38;5;241m.\u001b[39mcanonical_etypes:\n\u001b[0;32m    207\u001b[0m     rel_graph \u001b[38;5;241m=\u001b[39m g[stype, etype, dtype]\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m:\n\u001b[0;32m    209\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     dstdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module((stype, etype, dtype))(\n\u001b[0;32m    211\u001b[0m         rel_graph,\n\u001b[0;32m    212\u001b[0m         (inputs[stype], inputs[dtype]),\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;241m*\u001b[39mmod_args\u001b[38;5;241m.\u001b[39mget(etype, ()),\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmod_kwargs\u001b[38;5;241m.\u001b[39mget(etype, {})\n\u001b[0;32m    215\u001b[0m     )\n",
      "File \u001b[1;32md:\\PYTHON\\Lib\\site-packages\\torch\\_tensor.py:1118\u001b[0m, in \u001b[0;36mTensor.__contains__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1113\u001b[0m     element, (torch\u001b[38;5;241m.\u001b[39mTensor, Number, torch\u001b[38;5;241m.\u001b[39mSymInt, torch\u001b[38;5;241m.\u001b[39mSymFloat, torch\u001b[38;5;241m.\u001b[39mSymBool)\n\u001b[0;32m   1114\u001b[0m ):\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (element \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m-> 1118\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1120\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>."
     ]
    }
   ],
   "source": [
    "# training\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    # 使用所有节点的特征进行前向传播计算，并提取输出的user节点嵌入\n",
    "    logits = model(hetero_graph, node_features)['user']\n",
    "    # 计算损失值\n",
    "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "    # 计算验证集的准确度。在本例中省略。\n",
    "    # 进行反向传播计算\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
