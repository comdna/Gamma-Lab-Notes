{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "图数据集->图->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据集继承DGLDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import DGLDataset\n",
    "\n",
    "class MyDataset(DGLDataset):\n",
    "    def __init__(self,\n",
    "                url=None, #数据集的url\n",
    "                raw_dir=None,  # 下载数据的本地目录\n",
    "                save_dir=None, # 处理完数据集的保存目录\n",
    "                force_reload=False, # 是否重新导入数据集\n",
    "                verbose=False): # 是否打印进度信息\n",
    "        super(MyDataset, self).__init__(name='dataset_name',\n",
    "                                        url=url,\n",
    "                                        raw_dir=raw_dir,\n",
    "                                        save_dir=save_dir,\n",
    "                                        force_reload=force_reload,\n",
    "                                        verbose=verbose)\n",
    "\n",
    "    def download(self):\n",
    "        # 将原始数据下载到本地磁盘\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        # 将原始数据处理为图、标签和数据集划分的掩码\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 通过idx得到与之对应的一个样本\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        # 数据样本的数量\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        # 将处理后的数据保存至 `self.save_path`\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        # 从 `self.save_path` 导入处理后的数据\n",
    "        pass\n",
    "\n",
    "    def has_cache(self):\n",
    "        # 检查在 `self.save_path` 中是否存有处理后的数据\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载\n",
    "\n",
    "情况一：非压缩文件  \n",
    "情况二：压缩文件  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dgl.data.utils import download\n",
    "# 非压缩  实现把.mat文件下载到目录self.raw_dir里面\n",
    "def download(self):\n",
    "    # 存储文件的路径\n",
    "    file_path = os.path.join(self.raw_dir, self.name + '.mat')\n",
    "    # 下载文件\n",
    "    download(self.url, path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data.utils import download, check_sha1\n",
    "\n",
    "# 解压缩并且放到self.raw_dir里面,保存的文件名为self.name\n",
    "def download(self):\n",
    "    # 存储文件的路径，请确保使用与原始文件名相同的后缀\n",
    "    gz_file_path = os.path.join(self.raw_dir, self.name + '.csv.gz')\n",
    "    # 下载文件\n",
    "    download(self.url, path=gz_file_path)\n",
    "    # 检查 SHA-1\n",
    "    if not check_sha1(gz_file_path, self._sha1_str):\n",
    "        raise UserWarning('File {} is downloaded but the content hash does not match.'.format(self.name + '.csv.gz'))\n",
    "    # 将文件解压缩到目录self.raw_dir下的self.name目录中\n",
    "    self._extract_gz(gz_file_path, self.raw_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process、__getitem__ 、__len__\n",
    "\n",
    "对于多张图一起训练的，比如图分类等任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import DGLDataset\n",
    "\n",
    "class QM7bDataset(DGLDataset):\n",
    "    _url = 'http://deepchem.io.s3-website-us-west-1.amazonaws.com/' \\\n",
    "            'datasets/qm7b.mat'\n",
    "    _sha1_str = '4102c744bb9d6fd7b40ac67a300e49cd87e28392'\n",
    "\n",
    "    def __init__(self, raw_dir=None, force_reload=False, verbose=False):\n",
    "        super(QM7bDataset, self).__init__(name='qm7b',\n",
    "                                        url=self._url,\n",
    "                                        raw_dir=raw_dir,\n",
    "                                        force_reload=force_reload,\n",
    "                                        verbose=verbose)\n",
    "\n",
    "    def process(self):\n",
    "        mat_path = self.raw_path + '.mat'\n",
    "        # 将数据处理为图列表和标签列表\n",
    "        self.graphs, self.label = self._load_graph(mat_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #通过索引返回元组(图，标签)\n",
    "        \"\"\"\n",
    "        (dgl.DGLGraph, Tensor)\n",
    "        \"\"\"\n",
    "        return self.graphs[idx], self.label[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"数据集中 图的数量\"\"\"\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于单张图训练的，例如节点分类，链路预测等 __getitem()__ 和 __len__() 基本是写死的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(self):\n",
    "        # 跳过一些处理的代码\n",
    "        # === 跳过数据处理 ===\n",
    "\n",
    "        # 构建图\n",
    "        g = dgl.graph(graph)\n",
    "\n",
    "        # 划分掩码\n",
    "        g.ndata['train_mask'] = train_mask\n",
    "        g.ndata['val_mask'] = val_mask\n",
    "        g.ndata['test_mask'] = test_mask\n",
    "\n",
    "        # 节点的标签\n",
    "        g.ndata['label'] = torch.tensor(labels)\n",
    "        # 节点的特征\n",
    "        g.ndata['feat'] = torch.tensor(_preprocess_features(features),\n",
    "                                        dtype=F.data_type_dict['float32'])\n",
    "        self._num_tasks = onehot_labels.shape[1]\n",
    "        self._labels = labels\n",
    "        # 重排图以获得更优的局部性\n",
    "        self._g = dgl.reorder_graph(g)\n",
    "\n",
    "def __getitem__(self, idx):\n",
    "        assert idx == 0, \"这个数据集里只有一个图\"\n",
    "        return self._g\n",
    "\n",
    "def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save、load、has_cache\n",
    "\n",
    "dgl.save_graphs() 和 dgl.load_graphs():存图、读图\n",
    "\n",
    "dgl.data.utils.save_info() 和 dgl.data.utils.load_info(): 将数据集的有用信息(python dict对象)保存到本地磁盘和从本地磁盘读取它们"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dgl\n",
    "from dgl import save_graphs, load_graphs\n",
    "from dgl.data.utils import makedirs, save_info, load_info\n",
    "\n",
    "def save(self):\n",
    "    # 保存图和标签\n",
    "    graph_path = os.path.join(self.save_path, self.mode + '_dgl_graph.bin')\n",
    "    save_graphs(graph_path, self.graphs, {'labels': self.labels})\n",
    "    # 在Python字典里保存其他信息\n",
    "    info_path = os.path.join(self.save_path, self.mode + '_info.pkl')\n",
    "    save_info(info_path, {'num_classes': self.num_classes})\n",
    "\n",
    "def load(self):\n",
    "    # 从目录 `self.save_path` 里读取处理过的数据\n",
    "    graph_path = os.path.join(self.save_path, self.mode + '_dgl_graph.bin')\n",
    "    self.graphs, label_dict = load_graphs(graph_path)\n",
    "    self.labels = label_dict['labels']\n",
    "    info_path = os.path.join(self.save_path, self.mode + '_info.pkl')\n",
    "    self.num_classes = load_info(info_path)['num_classes']\n",
    "\n",
    "def has_cache(self):\n",
    "    # 检查在 `self.save_path` 里是否有处理过的数据文件\n",
    "    graph_path = os.path.join(self.save_path, self.mode + '_dgl_graph.bin')\n",
    "    info_path = os.path.join(self.save_path, self.mode + '_info.pkl')\n",
    "    return os.path.exists(graph_path) and os.path.exists(info_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
